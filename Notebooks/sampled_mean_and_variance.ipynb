{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras backend\n"
     ]
    }
   ],
   "source": [
    "from wmin.api import API as wminAPI\n",
    "from wmin.basis import FLAV_INFO\n",
    "import numpy as np\n",
    "import pandas as pd # import pandas for rolling average\n",
    "import matplotlib.pyplot as plt\n",
    "from colibri.constants import LHAPDF_XGRID\n",
    "\n",
    "# Set the path to the style file\n",
    "plt.style.use(\"../colibristyle_colorblind.mplstyle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = {\n",
    "    \"flav_info\": FLAV_INFO,\n",
    "    \"replica_range_settings\": {\"min_replica\": 1, \"max_replica\": 1000},\n",
    "    \"impose_sumrule\": True,\n",
    "    \"fitbasis\": \"EVOL\",\n",
    "    \"nodes\": [25, 20, 8],\n",
    "    \"activations\": [\"tanh\", \"tanh\", \"linear\"],\n",
    "    \"initializer_name\": \"glorot_normal\",\n",
    "    \"layer_type\": \"dense\",\n",
    "    \"filter_arclength_outliers\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markcostantini/arm64_miniconda3/envs/wmin-model-dev/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: {'pdf_input': 'pdf_input', 'xgrid_integration': 'xgrid_integration'}\n",
      "Received: inputs={'pdf_input': 'Tensor(shape=(1, 196, 1))', 'xgrid_integration': {'xgrid_integration': 'Tensor(shape=(1, 2000, 1))'}}\n",
      "  warnings.warn(msg)\n",
      "/Users/markcostantini/arm64_miniconda3/envs/wmin-model-dev/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: {'NN_input': 'NN_input'}\n",
      "Received: inputs=Tensor(shape=(1, 2000, 2))\n",
      "  warnings.warn(msg)\n",
      "/Users/markcostantini/arm64_miniconda3/envs/wmin-model-dev/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: {'NN_input': 'NN_input'}\n",
      "Received: inputs=Tensor(shape=(1, 196, 2))\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "samples_5k = wminAPI.n3fit_pdf_grid(**{**inp, \"replica_range_settings\": {\"min_replica\": 1, \"max_replica\": 5000},})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_convergence_rolling_avg(samples, grid_mask, step=10, start_n=500, rolling_window_size=15):\n",
    "    \"\"\"\n",
    "    Calculates the convergence of the running mean estimate,\n",
    "    smoothing the difference plot with a rolling average.\n",
    "\n",
    "    Args:\n",
    "        samples (np.ndarray): Array of samples, shape (N_total, dim1, dim2, ...).\n",
    "                              Assumes time/sample index is axis 0.\n",
    "        grid_mask (list or tuple): Start and end indices for the slice on the last axis.\n",
    "        step (int): Step size for calculating points to plot (reduces computation).\n",
    "        start_n (int): Minimum number of samples to start calculations from.\n",
    "        rolling_window_size (int): The window size for the rolling average smoothing.\n",
    "                                    Must be an odd number for centered average preferred.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The figure object.\n",
    "        matplotlib.axes._axes.Axes: The axes object.\n",
    "    \"\"\"\n",
    "    if rolling_window_size % 2 == 0:\n",
    "        print(\"Warning: rolling_window_size is even. Using center=True might shift results slightly. Consider an odd window size.\")\n",
    "\n",
    "    euclidean_distances = []\n",
    "    # Calculate range values respecting start_n and step\n",
    "    range_values = range(start_n, samples.shape[0] - 1, step) # Stop one early to calculate mu_N+1\n",
    "\n",
    "    # remove photon since it is zero\n",
    "    samples = samples[:, 1:, :]\n",
    "\n",
    "    print(f\"Calculating differences for N from {start_n} to {samples.shape[0]-2} with step {step}...\")\n",
    "    for i in range_values:\n",
    "        # Slice the data ONCE efficiently\n",
    "        samples_slice = samples[: i + 1, :, grid_mask[0]:grid_mask[1]]\n",
    "        # Calculate means\n",
    "        mu_N = np.mean(samples_slice[:-1, :, :], axis=0) # Mean up to i\n",
    "        mu_N_plus_one = np.mean(samples_slice, axis=0)    # Mean up to i+1\n",
    "\n",
    "        # Calculate the norm of the difference vector\n",
    "        euclidean_distance = np.linalg.norm(mu_N - mu_N_plus_one)\n",
    "        euclidean_distances.append(euclidean_distance)\n",
    "    print(\"Calculation complete.\")\n",
    "\n",
    "    # --- Smoothing with Rolling Average ---\n",
    "    # Convert to pandas Series for easy rolling calculation\n",
    "    distances_series = pd.Series(euclidean_distances)\n",
    "    # Calculate rolling average - center=True is usually better for smoothing trends\n",
    "    # min_periods=1 ensures output even for initial points where window isn't full\n",
    "    smoothed_distances = distances_series.rolling(\n",
    "        window=rolling_window_size,\n",
    "        center=True,\n",
    "        min_periods=1 # Start smoothing immediately\n",
    "    ).mean()\n",
    "    # Note: center=True will produce NaNs at the very start/end if min_periods isn't set\n",
    "    # or if it's larger than half the window. min_periods=1 avoids this.\n",
    "\n",
    "    return euclidean_distances, smoothed_distances, range_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_convergence_rolling_avg(samples, grid_mask, step=10, start_n=500, rolling_window_size=15):\n",
    "    \"\"\"\n",
    "    Calculates the convergence of the running correlation estimate,\n",
    "    smoothing the difference plot with a rolling average.\n",
    "\n",
    "    Args:\n",
    "        samples (np.ndarray): Array of samples, shape (N_total, dim1, dim2, ...).\n",
    "                              Assumes time/sample index is axis 0.\n",
    "        grid_mask (list or tuple): Start and end indices for the slice on the last axis.\n",
    "        step (int): Step size for calculating points to plot (reduces computation).\n",
    "        start_n (int): Minimum number of samples to start calculations from.\n",
    "        rolling_window_size (int): The window size for the rolling average smoothing.\n",
    "                                    Must be an odd number for centered average preferred.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The figure object.\n",
    "        matplotlib.axes._axes.Axes: The axes object.\n",
    "    \"\"\"\n",
    "    if rolling_window_size % 2 == 0:\n",
    "        print(\"Warning: rolling_window_size is even. Using center=True might shift results slightly. Consider an odd window size.\")\n",
    "\n",
    "    frobenius_norms = []\n",
    "    # Calculate range values respecting start_n and step\n",
    "    range_values = range(start_n, samples.shape[0] - 1, step) # Stop one early to calculate mu_N+1\n",
    "\n",
    "    # reshape samples\n",
    "    samples = samples[:, :, grid_mask[0]:grid_mask[1]]\n",
    "    # remove photon since it is zero\n",
    "    samples = samples[:, 1:, :]\n",
    "    samples = samples.reshape(samples.shape[0], samples.shape[1] * samples.shape[2])\n",
    "    \n",
    "\n",
    "    print(f\"Calculating differences for N from {start_n} to {samples.shape[0]-2} with step {step}...\")\n",
    "    for i in range_values:\n",
    "        # Slice the data ONCE efficiently\n",
    "        samples_slice = samples[: i + 1, :]\n",
    "        # Calculate Correlation matrices\n",
    "        corr_N = np.corrcoef(samples_slice[:-1, :], rowvar=False) # Correlation up to i\n",
    "        corr_N_plus_one = np.corrcoef(samples_slice, rowvar=False)    # Correlation up to i+1\n",
    "\n",
    "        # Calculate the frobenius norm of the difference vector\n",
    "        frob_norm = np.linalg.norm(corr_N - corr_N_plus_one, ord='fro')\n",
    "        frobenius_norms.append(frob_norm)\n",
    "\n",
    "    print(\"Calculation complete.\")\n",
    "\n",
    "    # --- Smoothing with Rolling Average ---\n",
    "    # Convert to pandas Series for easy rolling calculation\n",
    "    distances_series = pd.Series(frobenius_norms)\n",
    "    # Calculate rolling average - center=True is usually better for smoothing trends\n",
    "    # min_periods=1 ensures output even for initial points where window isn't full\n",
    "    smoothed_distances = distances_series.rolling(\n",
    "        window=rolling_window_size,\n",
    "        center=True,\n",
    "        min_periods=1 # Start smoothing immediately\n",
    "    ).mean()\n",
    "    # Note: center=True will produce NaNs at the very start/end if min_periods isn't set\n",
    "    # or if it's larger than half the window. min_periods=1 avoids this.\n",
    "\n",
    "    return frobenius_norms, smoothed_distances, range_values\n",
    "\n",
    "\n",
    "def variance_convergence_rolling_avg(samples, grid_mask, step=10, start_n=500, rolling_window_size=15):\n",
    "    \"\"\"\n",
    "    Calculates the convergence of the running variance estimate,\n",
    "    smoothing the difference plot with a rolling average.\n",
    "\n",
    "    Args:\n",
    "        samples (np.ndarray): Array of samples, shape (N_total, dim1, dim2, ...).\n",
    "                              Assumes time/sample index is axis 0.\n",
    "        grid_mask (list or tuple): Start and end indices for the slice on the last axis.\n",
    "        step (int): Step size for calculating points to plot (reduces computation).\n",
    "        start_n (int): Minimum number of samples to start calculations from.\n",
    "        rolling_window_size (int): The window size for the rolling average smoothing.\n",
    "                                    Must be an odd number for centered average preferred.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The figure object.\n",
    "        matplotlib.axes._axes.Axes: The axes object.\n",
    "    \"\"\"\n",
    "    if rolling_window_size % 2 == 0:\n",
    "        print(\"Warning: rolling_window_size is even. Using center=True might shift results slightly. Consider an odd window size.\")\n",
    "\n",
    "    frobenius_norms = []\n",
    "    # Calculate range values respecting start_n and step\n",
    "    range_values = range(start_n, samples.shape[0] - 1, step) # Stop one early to calculate mu_N+1\n",
    "\n",
    "    # reshape samples\n",
    "    samples = samples[:, :, grid_mask[0]:grid_mask[1]]\n",
    "    # remove photon since it is zero\n",
    "    samples = samples[:, 1:, :]\n",
    "    samples = samples.reshape(samples.shape[0], samples.shape[1] * samples.shape[2])\n",
    "    \n",
    "\n",
    "    print(f\"Calculating differences for N from {start_n} to {samples.shape[0]-2} with step {step}...\")\n",
    "    for i in range_values:\n",
    "        # Slice the data ONCE efficiently\n",
    "        samples_slice = samples[: i + 1, :]\n",
    "        # Calculate Correlation matrices\n",
    "        var_N = np.diag(np.cov(samples_slice[:-1, :], rowvar=False)) # variance up to i\n",
    "        var_N_plus_one = np.diag(np.cov(samples_slice, rowvar=False))    # variance up to i+1\n",
    "\n",
    "        # Calculate the norm of the difference vector\n",
    "        frob_norm = np.linalg.norm(var_N - var_N_plus_one)\n",
    "        frobenius_norms.append(frob_norm)\n",
    "\n",
    "    print(\"Calculation complete.\")\n",
    "\n",
    "    # --- Smoothing with Rolling Average ---\n",
    "    # Convert to pandas Series for easy rolling calculation\n",
    "    distances_series = pd.Series(frobenius_norms)\n",
    "    # Calculate rolling average - center=True is usually better for smoothing trends\n",
    "    # min_periods=1 ensures output even for initial points where window isn't full\n",
    "    smoothed_distances = distances_series.rolling(\n",
    "        window=rolling_window_size,\n",
    "        center=True,\n",
    "        min_periods=1 # Start smoothing immediately\n",
    "    ).mean()\n",
    "    # Note: center=True will produce NaNs at the very start/end if min_periods isn't set\n",
    "    # or if it's larger than half the window. min_periods=1 avoids this.\n",
    "\n",
    "    return frobenius_norms, smoothed_distances, range_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_10k = wminAPI.n3fit_pdf_grid(**{**inp, \"replica_range_settings\": {\"min_replica\": 1, \"max_replica\": 10000},})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_20k = wminAPI.n3fit_pdf_grid(**{**inp, \"replica_range_settings\": {\"min_replica\": 1, \"max_replica\": 20000},})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.29841683435992e-05 0.61723395978245\n"
     ]
    }
   ],
   "source": [
    "# Define the grid mask\n",
    "grid_mask = [40, 150] # Use almost the full grid for the example\n",
    "print(np.min(LHAPDF_XGRID[grid_mask[0]:grid_mask[1]]), np.max(LHAPDF_XGRID[grid_mask[0]:grid_mask[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markcostantini/arm64_miniconda3/envs/wmin-model-dev/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: {'pdf_input': 'pdf_input', 'xgrid_integration': 'xgrid_integration'}\n",
      "Received: inputs={'pdf_input': 'Tensor(shape=(1, 196, 1))', 'xgrid_integration': {'xgrid_integration': 'Tensor(shape=(1, 2000, 1))'}}\n",
      "  warnings.warn(msg)\n",
      "/Users/markcostantini/arm64_miniconda3/envs/wmin-model-dev/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: {'NN_input': 'NN_input'}\n",
      "Received: inputs=Tensor(shape=(1, 2000, 2))\n",
      "  warnings.warn(msg)\n",
      "/Users/markcostantini/arm64_miniconda3/envs/wmin-model-dev/lib/python3.12/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: {'NN_input': 'NN_input'}\n",
      "Received: inputs=Tensor(shape=(1, 196, 2))\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "samples_40k = wminAPI.n3fit_pdf_grid(**{**inp, \"replica_range_settings\": {\"min_replica\": 1, \"max_replica\": 40000},})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating differences for N from 500 to 35887 with step 50...\n",
      "Calculation complete.\n"
     ]
    }
   ],
   "source": [
    "# Define the grid mask\n",
    "grid_mask = [40, 150] # Use almost the full grid for the example\n",
    "\n",
    "# Compute the convergence of the mean using the rolling average function\n",
    "eucl_mean, smoothed_mean, range_vals_mean = mean_convergence_rolling_avg(\n",
    "    samples_40k,\n",
    "    grid_mask,\n",
    "    step=50, # Calculate fewer points to speed up plotting\n",
    "    start_n=500,\n",
    "    rolling_window_size=31, # Use an odd number for centered window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating differences for N from 500 to 35887 with step 50...\n",
      "Calculation complete.\n"
     ]
    }
   ],
   "source": [
    "# Compute the correlation convergence using the rolling average function\n",
    "frob_corr, smoothed_corr, range_vals_corr = correlation_convergence_rolling_avg(\n",
    "    samples_40k,\n",
    "    grid_mask,\n",
    "    step=50, # Calculate fewer points to speed up plotting\n",
    "    start_n=500,\n",
    "    rolling_window_size=31, # Use an odd number for centered window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating differences for N from 500 to 35887 with step 50...\n",
      "Calculation complete.\n"
     ]
    }
   ],
   "source": [
    "# Compute the variance convergence using the rolling average function\n",
    "euclid_var, smoothed_var, range_vals_var = variance_convergence_rolling_avg(\n",
    "    samples_40k,\n",
    "    grid_mask,\n",
    "    step=50, # Calculate fewer points to speed up plotting\n",
    "    start_n=500,\n",
    "    rolling_window_size=31, # Use an odd number for centered window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot ready.\n",
      "<Figure size 1000x700 with 1 Axes>\n"
     ]
    }
   ],
   "source": [
    "# plot the convergence of the mean and correlation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "# Plot the raw (unsmoothed) distances lightly for reference\n",
    "# ax.plot(range_vals_mean, eucl_mean, label=r\"Raw Difference $||\\mu_N - \\mu_{N+1}||$\", linestyle='-', linewidth=3)\n",
    "\n",
    "# Plot the smoothed distances\n",
    "max_idx = np.where(np.array(range_vals_mean) > 20000)[0][0]\n",
    "ax.plot(range_vals_mean[:max_idx], smoothed_mean[:max_idx], label=r\"$||\\mu_N - \\mu_{N+1}||$\", linewidth=4)\n",
    "DIV_FAC = 30\n",
    "ax.plot(range_vals_corr[:max_idx], smoothed_corr[:max_idx] / DIV_FAC , label=r\"$||\\rho_N - \\rho_{N+1}||$\" + f\"/{DIV_FAC}\", linewidth=4)\n",
    "\n",
    "ax.plot(range_vals_var[:max_idx], smoothed_var[:max_idx] / 10, label=r\"$||\\sigma_N - \\sigma_{N+1}||$/10\", linewidth=4)\n",
    "\n",
    "# Reference line (optional, can be adjusted based on expected noise floor)\n",
    "ax.axhline(y=0.0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Style improvements\n",
    "ax.set_xlabel(\"Number of Samples (N)\", fontsize=24)\n",
    "ax.set_ylabel(r\"Euclidean Distance\", fontsize=24)\n",
    "ax.set_title(\"Convergence of Running Estimate\", fontsize=24)\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "ax.legend(fontsize=16)\n",
    "ax.grid(True, which=\"both\", linestyle='--', linewidth=0.5,) # Grid for both axes\n",
    "\n",
    "# Improve readability\n",
    "plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
    "print(\"Plot ready.\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.savefig(f\"nn_distribution_convergence.pdf\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wmin-model-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
